import os
import json
import requests
from flask import Flask, request, jsonify, send_from_directory
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv

# ============================================================
# 1Ô∏è‚É£ C·∫•u h√¨nh m√¥i tr∆∞·ªùng
# ============================================================
load_dotenv()

OLLAMA_HOST = os.getenv('OLLAMA_HOST', 'http://localhost:11434')
MODEL_NAME = os.getenv('OLLAMA_MODEL', 'ontocord/vistral:latest')
CHROMA_DIR = os.getenv('CHROMA_PERSIST_DIR', './chroma_db')

# ============================================================
# 2Ô∏è‚É£ Kh·ªüi t·∫°o Chroma + m√¥ h√¨nh embedding
# ============================================================
client = chromadb.Client(Settings(persist_directory=CHROMA_DIR))
try:
    collection = client.get_collection('hutech_docs')
except Exception:
    collection = client.create_collection(name='hutech_docs')

embed_model = SentenceTransformer('all-mpnet-base-v2')

# ============================================================
# 3Ô∏è‚É£ Flask app
# ============================================================
app = Flask(__name__)

PROMPT_TEMPLATE = """
B·∫°n l√† Chatbot HUTECH ü§ñ ‚Äî m·ªôt tr·ª£ l√Ω AI th√¢n thi·ªán, th√¥ng minh v√† hi·ªÉu bi·∫øt, ƒë∆∞·ª£c t·∫°o ra ƒë·ªÉ gi√∫p ƒë·ª° sinh vi√™n v√† nh·ªØng ng∆∞·ªùi quan t√¢m ƒë·∫øn HUTECH.

H√£y lu√¥n n√≥i chuy·ªán v·ªõi gi·ªçng vƒÉn t·ª± nhi√™n, g·∫ßn g≈©i nh∆∞ m·ªôt ng∆∞·ªùi b·∫°n, m·ªôt sinh vi√™n HUTECH ƒëang gi√∫p ƒë·ª° b·∫°n b√®.
Lu√¥n x∆∞ng h√¥ l√† "m√¨nh" v√† "b·∫°n".

ƒê√¢y l√† quy tr√¨nh tr·∫£ l·ªùi c·ªßa b·∫°n:

1.  **∆ØU TI√äN H√ÄNG ƒê·∫¶U (Th√¥ng tin HUTECH):**
    H√£y ki·ªÉm tra k·ªπ "T√†i li·ªáu tham kh·∫£o" b√™n d∆∞·ªõi. N·∫øu c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng c√≥ th·ªÉ ƒë∆∞·ª£c tr·∫£ l·ªùi b·∫±ng th√¥ng tin n√†y, H√ÉY B·∫ÆT BU·ªòC s·ª≠ d·ª•ng n√≥ ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi ch√≠nh x√°c nh·∫•t. ƒê√¢y l√† ngu·ªìn th√¥ng tin ch√≠nh th·ª©c v√† ƒë√°ng tin c·∫≠y.

2.  **KHI KH√îNG C√ì T√ÄI LI·ªÜU (Ki·∫øn th·ª©c chung):**
    N·∫øu "T√†i li·ªáu tham kh·∫£o" kh√¥ng ch·ª©a th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi, H√ÉY S·ª¨ D·ª§NG ki·∫øn th·ª©c chung c·ªßa b·∫°n (v·ªõi t∆∞ c√°ch l√† m·ªôt m√¥ h√¨nh AI l·ªõn) ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi ƒë√≥ m·ªôt c√°ch t·ªët nh·∫•t c√≥ th·ªÉ. ƒê·ª´ng n√≥i "M√¨nh ch∆∞a c√≥ th√¥ng tin n√†y".

3.  **QUY T·∫ÆC CH√ÄO H·ªéI:**
    Khi ng∆∞·ªùi d√πng ch√†o (v√≠ d·ª•: "xin ch√†o", "hello", "hi"), h√£y ph·∫£n h·ªìi t·ª± nhi√™n, th√¢n thi·ªán v√† gi·ªõi thi·ªáu b·∫£n th√¢n ng·∫Øn g·ªçn, v√≠ d·ª•:
    "Ch√†o b·∫°n üëã M√¨nh l√† Chatbot HUTECH. M√¨nh c√≥ th·ªÉ gi√∫p b·∫°n t√¨m hi·ªÉu th√¥ng tin v·ªÅ h·ªçc ph√≠, tuy·ªÉn sinh, ho·∫∑c b·∫•t c·ª© ƒëi·ªÅu g√¨ b·∫°n t√≤ m√≤!"

4.  **PHONG C√ÅCH:**
    Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, r√µ r√†ng, ng·∫Øn g·ªçn v√† ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ.

=== T√†i li·ªáu tham kh·∫£o ===
{chunks}

=== C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng ===
{question}

=== C√¢u tr·∫£ l·ªùi c·ªßa b·∫°n ===
"""


# ============================================================
# 4Ô∏è‚É£ Trang giao di·ªán ch√≠nh
# ============================================================
@app.route('/')
def index_page():
    return send_from_directory(os.path.dirname(__file__), 'index.html')

# ============================================================
# 5Ô∏è‚É£ H√†m build text cho c√°c ƒëo·∫°n t√†i li·ªáu
# ============================================================
def build_chunks_text(hits):
    lines = []
    for item in hits:
        meta = item['metadata']
        doc = item['document']
        lines.append(
            f"Source: {meta.get('source')} | chunk_id: {meta.get('chunk_id')} "
            f"| paras: {meta.get('start_para')}-{meta.get('end_para')}\n{doc}"
        )
    return "\n\n".join(lines)

# ============================================================
# 6Ô∏è‚É£ API /query
# ============================================================
@app.route('/query', methods=['POST'])
def query():
    data = request.json
    q = data.get('question')
    k = int(data.get('k', 4))

    if not q:
        return jsonify({'error': 'Missing question'}), 400

    # T·∫°o embedding cho c√¢u h·ªèi
    q_emb = embed_model.encode([q])[0].tolist()

    # T√¨m ki·∫øm trong vectorstore
    hits_raw = collection.query(
        query_embeddings=[q_emb],
        n_results=k,
        include=['documents', 'metadatas', 'distances']
    )

    docs = []
    for doc, meta, dist in zip(
        hits_raw['documents'][0],
        hits_raw['metadatas'][0],
        hits_raw['distances'][0]
    ):
        docs.append({'document': doc, 'metadata': meta, 'distance': dist})

    chunks_text = build_chunks_text(docs)
    prompt = PROMPT_TEMPLATE.format(chunks=chunks_text, question=q)

    # G·ª≠i request t·ªõi Ollama (s·ª≠a l·ªói Extra data)
    payload = {
        'model': MODEL_NAME,
        'prompt': prompt,
        'max_tokens': 512,
        'temperature': 0.0
    }

    try:
        resp = requests.post(
            f"{OLLAMA_HOST}/api/generate",
            json=payload,
            stream=True,
            timeout=120
        )
        resp.raise_for_status()

        out_text = ""
        for line in resp.iter_lines():
            if line:
                try:
                    data = json.loads(line.decode('utf-8'))
                    out_text += data.get("response", "")
                except json.JSONDecodeError:
                    continue

        out = {"response": out_text}

    except Exception as e:
        return jsonify({'error': f'Call to Ollama failed: {str(e)}'}), 500

    # X·ª≠ l√Ω k·∫øt qu·∫£
    answer = out.get("response", "Kh√¥ng c√≥ ph·∫£n h·ªìi t·ª´ m√¥ h√¨nh.")

    return jsonify({
        'answer': answer,
        'sources': [
            {
                'source': d['metadata']['source'],
                'chunk_id': d['metadata']['chunk_id'],
                'paras': f"{d['metadata']['start_para']}-{d['metadata']['end_para']}",
                'distance': d['distance']
            }
            for d in docs
        ]
    })

# ============================================================
# 7Ô∏è‚É£ Ch·∫°y server Flask
# ============================================================
if __name__ == '__main__':
    port = int(os.getenv('FLASK_PORT', 7860))
    app.run(host='0.0.0.0', port=port, debug=True)
