import os
import json
import requests
from flask import Flask, request, jsonify, send_from_directory
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv

# ============================================================
# 1Ô∏è‚É£ C·∫•u h√¨nh m√¥i tr∆∞·ªùng
# ============================================================
load_dotenv()

OLLAMA_HOST = os.getenv('OLLAMA_HOST', 'http://localhost:11434')
MODEL_NAME = os.getenv('OLLAMA_MODEL', 'ontocord/vistral:latest')
CHROMA_DIR = os.getenv('CHROMA_PERSIST_DIR', './chroma_db')

# ============================================================
# 2Ô∏è‚É£ Kh·ªüi t·∫°o Chroma + m√¥ h√¨nh embedding
# ============================================================
client = chromadb.Client(Settings(persist_directory=CHROMA_DIR))
try:
    collection = client.get_collection('hutech_docs')
except Exception:
    collection = client.create_collection(name='hutech_docs')

embed_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')

# ============================================================
# 3Ô∏è‚É£ Flask app
# ============================================================
app = Flask(__name__)

PROMPT_TEMPLATE = """
B·∫°n l√† Chatbot HUTECH ü§ñ ‚Äî m·ªôt tr·ª£ l√Ω AI th√¢n thi·ªán, th√¥ng minh v√† hi·ªÉu bi·∫øt, ƒë∆∞·ª£c t·∫°o ra ƒë·ªÉ gi√∫p ƒë·ª° sinh vi√™n v√† nh·ªØng ng∆∞·ªùi quan t√¢m ƒë·∫øn HUTECH.

H√£y lu√¥n n√≥i chuy·ªán v·ªõi gi·ªçng vƒÉn t·ª± nhi√™n, g·∫ßn g≈©i nh∆∞ m·ªôt ng∆∞·ªùi b·∫°n, m·ªôt sinh vi√™n HUTECH ƒëang gi√∫p ƒë·ª° b·∫°n b√®.
Lu√¥n x∆∞ng h√¥ l√† "m√¨nh" v√† "b·∫°n".

ƒê√¢y l√† quy tr√¨nh tr·∫£ l·ªùi c·ªßa b·∫°n:

1.  **∆ØU TI√äN H√ÄNG ƒê·∫¶U (Th√¥ng tin HUTECH):**
    H√£y ki·ªÉm tra k·ªπ "T√†i li·ªáu tham kh·∫£o" b√™n d∆∞·ªõi. N·∫øu c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng c√≥ th·ªÉ ƒë∆∞·ª£c tr·∫£ l·ªùi b·∫±ng th√¥ng tin n√†y, H√ÉY B·∫ÆT BU·ªòC s·ª≠ d·ª•ng n√≥ ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi ch√≠nh x√°c nh·∫•t. ƒê√¢y l√† ngu·ªìn th√¥ng tin ch√≠nh th·ª©c.

2.  **KHI KH√îNG C√ì T√ÄI LI·ªÜU (X·ª≠ l√Ω th√¥ng minh):**
    N·∫øu "T√†i li·ªáu tham kh·∫£o" kh√¥ng ch·ª©a th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi, h√£y ki·ªÉm tra:

    * **A) N·∫øu c√¢u h·ªèi V·∫™N v·ªÅ HUTECH (v√≠ d·ª•: "K√Ω t√∫c x√° HUTECH c√≥ cho nu√¥i m√®o kh√¥ng?"):**
        H√ÉY TR·∫¢ L·ªúI TH·∫¨T TH√Ä r·∫±ng b·∫°n kh√¥ng t√¨m th·∫•y th√¥ng tin ch√≠nh th·ª©c.
        V√≠ d·ª•: "√îi, v·ªÅ v·ª• [ch·ªß ƒë·ªÅ c√¢u h·ªèi] th√¨ m√¨nh ch∆∞a t√¨m th·∫•y th√¥ng tin ch√≠nh th·ª©c trong t√†i li·ªáu c·ªßa m√¨nh r·ªìi. B·∫°n th·ª≠ li√™n h·ªá tr·ª±c ti·∫øp v·ªõi ph√≤ng/ban li√™n quan ƒë·ªÉ ch·∫Øc ch·∫Øn nh·∫•t nh√©!"

    * **B) N·∫øu c√¢u h·ªèi KH√îNG v·ªÅ HUTECH (v√≠ d·ª•: "H√¥m nay ƒÉn g√¨?", "Th·ªß ƒë√¥ c·ªßa Ph√°p l√† g√¨?"):**
        B·∫°n c√≥ th·ªÉ tho·∫£i m√°i d√πng ki·∫øn th·ª©c chung c·ªßa m√¨nh ƒë·ªÉ tr·∫£ l·ªùi nh∆∞ m·ªôt ng∆∞·ªùi b·∫°n.
        V√≠ d·ª•: "H√¨, v·ª• n√†y th√¨ ngo√†i chuy√™n m√¥n HUTECH c·ªßa m√¨nh, nh∆∞ng theo m√¨nh bi·∫øt th√¨..."

3.  **QUY T·∫ÆC CH√ÄO H·ªéI:**
    Khi ng∆∞·ªùi d√πng ch√†o (v√≠ d·ª•: "xin ch√†o", "hello", "hi"), h√£y ph·∫£n h·ªìi t·ª± nhi√™n, th√¢n thi·ªán v√† gi·ªõi thi·ªáu b·∫£n th√¢n ng·∫Øn g·ªçn.

4.  **PHONG C√ÅCH:**
    Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, r√µ r√†ng, ng·∫Øn g·ªçn v√† ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ.

5.  **QUY T·∫ÆC TR√çCH D·∫™N:**
    Khi b·∫°n tr·∫£ l·ªùi d·ª±a tr√™n "T√†i li·ªáu tham kh·∫£o" (Quy t·∫Øc 1), H√ÉY LU√îN tr√≠ch d·∫´n ngu·ªìn tin c·∫≠y ·ªü cu·ªëi c√¢u tr·∫£ l·ªùi.
    V√≠ d·ª•: "... (Ngu·ªìn: ten_file.docx, ƒëo·∫°n {{start_para}}-{{end_para}})."
    (B·∫°n s·∫Ω l·∫•y th√¥ng tin n√†y t·ª´ ph·∫ßn `Source:` v√† `paras:` trong T√†i li·ªáu tham kh·∫£o).
=== T√†i li·ªáu tham kh·∫£o ===
{chunks}

=== C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng ===
{question}

=== C√¢u tr·∫£ l·ªùi c·ªßa b·∫°n ===
"""


# ============================================================
# 4Ô∏è‚É£ Trang giao di·ªán ch√≠nh
# ============================================================
@app.route('/')
def index_page():
    return send_from_directory(os.path.dirname(__file__), 'index.html')

# ============================================================
# 5Ô∏è‚É£ H√†m build text cho c√°c ƒëo·∫°n t√†i li·ªáu
# ============================================================
def build_chunks_text(hits):
    lines = []
    for item in hits:
        meta = item['metadata']
        doc = item['document']
        lines.append(
            # Format l·∫°i ƒë·ªÉ AI d·ªÖ ƒë·ªçc h∆°n
            f"[Ngu·ªìn: {meta.get('source')} | ƒêo·∫°n: {meta.get('start_para')}-{meta.get('end_para')}]\n"
            f"N·ªôi dung: {doc}"
        )
    return "\n\n".join(lines)

# ============================================================
# 6Ô∏è‚É£ API /query
# ============================================================
@app.route('/query', methods=['POST'])
def query():
    data = request.json
    q = data.get('question')
    k = int(data.get('k', 4))

    if not q:
        return jsonify({'error': 'Missing question'}), 400

    # T·∫°o embedding cho c√¢u h·ªèi
    q_emb = embed_model.encode([q])[0].tolist()

    # T√¨m ki·∫øm trong vectorstore
    hits_raw = collection.query(
        query_embeddings=[q_emb],
        n_results=k,
        include=['documents', 'metadatas', 'distances']
    )

    docs = []
    for doc, meta, dist in zip(
        hits_raw['documents'][0],
        hits_raw['metadatas'][0],
        hits_raw['distances'][0]
    ):
        docs.append({'document': doc, 'metadata': meta, 'distance': dist})

    chunks_text = build_chunks_text(docs)
    prompt = PROMPT_TEMPLATE.format(chunks=chunks_text, question=q)

    # G·ª≠i request t·ªõi Ollama (s·ª≠a l·ªói Extra data)
    payload = {
        'model': MODEL_NAME,
        'prompt': prompt,
        'max_tokens': 512,
        'temperature': 0.0
    }

    try:
        resp = requests.post(
            f"{OLLAMA_HOST}/api/generate",
            json=payload,
            stream=True,
            timeout=120
        )
        resp.raise_for_status()

        out_text = ""
        for line in resp.iter_lines():
            if line:
                try:
                    data = json.loads(line.decode('utf-8'))
                    out_text += data.get("response", "")
                except json.JSONDecodeError:
                    continue

        out = {"response": out_text}

    except Exception as e:
        return jsonify({'error': f'Call to Ollama failed: {str(e)}'}), 500

    # X·ª≠ l√Ω k·∫øt qu·∫£
    answer = out.get("response", "Kh√¥ng c√≥ ph·∫£n h·ªìi t·ª´ m√¥ h√¨nh.")

    return jsonify({
        'answer': answer,
        'sources': [
            {
                'source': d['metadata']['source'],
                'chunk_id': d['metadata']['chunk_id'],
                'paras': f"{d['metadata']['start_para']}-{d['metadata']['end_para']}",
                'distance': d['distance']
            }
            for d in docs
        ]
    })

# ============================================================
# 7Ô∏è‚É£ Ch·∫°y server Flask
# ============================================================
if __name__ == '__main__':
    port = int(os.getenv('FLASK_PORT', 7860))
    app.run(host='0.0.0.0', port=port, debug=True)
